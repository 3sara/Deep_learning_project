{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aa9ssRQXOF9F"
   },
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):    \n",
    "    def __init__(self, weather_data = 'data/big_arpafvg.csv', img_dir = 'data/cut_images', seq_length = 7):\n",
    "        \n",
    "        # Load weather data\n",
    "        weather_data=pd.read_csv(weather_data)\n",
    "        # Drop columns that are not useful\n",
    "        weather_data = weather_data.drop(columns=['Temp. min gradi C','Temp. med gradi C','Temp. max gradi C','Vento med km/h','Dir. V. max gradi N'])\n",
    "        # Normalize data\n",
    "        for col in weather_data.columns:\n",
    "            if col != 'giorno' and col != 'mese' and col != 'anno':\n",
    "                weather_data[col] = (weather_data[col] - weather_data[col].mean()) / weather_data[col].std()\n",
    "\n",
    "        \n",
    "        \n",
    "        self.weather_data = weather_data\n",
    "        self.img_dir = img_dir\n",
    "        self.seq_length = seq_length\n",
    "        self.target_column_index = None\n",
    "        self.date_generated = []\n",
    "\n",
    "    def __getitem__(self, start_date):\n",
    "        \"\"\"\n",
    "        Gets the image and the weather data for a given start_date\n",
    "        Returns: [image, weather_data]\n",
    "        image: torch.tensor\n",
    "        weather_data: torch.tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # Get day, month, year from start_date in format dd-mm-yyyy\n",
    "        day, month, year = start_date.split('_')\n",
    "\n",
    "        # Get from weather data the row with the such start_date\n",
    "        weather_data = self.weather_data[(self.weather_data['giorno'] == int(day)) & (self.weather_data['mese'] == int(month)) & (self.weather_data['anno'] == int(year))]\n",
    "        # One hot encoding for the month column\n",
    "        weather_data = pd.get_dummies(weather_data, columns=['mese'], dtype=int)\n",
    "        #Get the index of the targe column \"log(Pioggia mm)\"\n",
    "        self.target_colum_index = weather_data.columns.get_loc('log(Pioggia mm)')\n",
    "        # Torchify the data\n",
    "        weather_data = torch.tensor(weather_data.values[0])\n",
    "\n",
    "        # Get the image for the such start_date\n",
    "        image = os.path.join(self.img_dir, str(start_date) + '.jpg')  \n",
    "        image = read_image(image)\n",
    "\n",
    "        return [image, weather_data]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.weather_data)\n",
    "\n",
    "    def date_generation(self, start_date, end_date):\n",
    "        \"\"\"\n",
    "        Generates a list of dates between start_date and end_date\n",
    "        The dates are in format dd-mm-yyyy\n",
    "        Returns: list of strings\n",
    "        \"\"\"\n",
    "\n",
    "        start_date = datetime.strptime(start_date, \"%d_%m_%Y\")\n",
    "        end_date = datetime.strptime(end_date, \"%d_%m_%Y\")\n",
    "\n",
    "        # Generate a list of datetime objects\n",
    "        date_generated = [start_date + timedelta(days=x) for x in range(0, (end_date-start_date).days)]\n",
    "\n",
    "        #Transform the list of datetime objects in a list of strings in format dd-mm-yyyy\n",
    "        date_generated = [start_date.strftime(\"%d_%m_%Y\") for start_date in date_generated]\n",
    "        self.date_generated=date_generated\n",
    "\n",
    "        return date_generated\n",
    "    \n",
    "    def create_sequence(self, dates_list, len_seq):\n",
    "        \"\"\"\n",
    "        This method gets a list of dates in format dd_mm_yyyy and \n",
    "        creates a sequence of images, weather data and target values of len_seq days.\n",
    "        \n",
    "        Returns: batch_imgs, batch_xs, batch_ys\n",
    "\n",
    "        batch_imgs: torch.tensor of shape (len(dates_list), len_seq, n_channels, height, width)\n",
    "        batch_xs: torch.tensor of shape (len(dates_list), len_seq, n_features_weather_data)\n",
    "        batch_ys: torch.tensor of shape (len(dates_list), 1)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        batch_imgs = []\n",
    "        batch_xs =[]\n",
    "        batch_ys = []\n",
    "        \n",
    "        for start_date in dates_list:\n",
    "            \n",
    "            # Get the end date of the sequence\n",
    "            end_date = start_date.split('_')\n",
    "            end_date = datetime(int(end_date[2]), int(end_date[1]), int(end_date[0])) + timedelta(days = len_seq)\n",
    "            end_date = end_date.strftime(\"%d_%m_%Y\")\n",
    "            \n",
    "            # List of images, weather data and target values\n",
    "            imgs, xs, ys = [], [], []\n",
    "\n",
    "            # Generate the list of dates between start_date and end_date            \n",
    "            date_sequence = self.date_generation(start_date, end_date)\n",
    "            \n",
    "            # Append the image and weather data to imgs and xs\n",
    "            for day in date_sequence:\n",
    "                img, x = self.__getitem__(day)\n",
    "                imgs.append(img)\n",
    "                xs.append(x)\n",
    "\n",
    "            # Get the day after the end_date\n",
    "            end_date_next = end_date.split('_')\n",
    "            end_date_next = datetime(int(end_date_next[2]), int(end_date_next[1]), int(end_date_next[0])) + timedelta(days = 1)\n",
    "            end_date_next = end_date_next.strftime(\"%d_%m_%Y\")\n",
    "\n",
    "            # Append the target value to ys\n",
    "            ys.append(self.__getitem__(end_date_next)[1][self.target_column_index])\n",
    "\n",
    "            # Convert the lists to torch tensors\n",
    "            imgs = torch.from_numpy(np.array(imgs)).float()\n",
    "            xs = torch.from_numpy(np.array(xs)).float()\n",
    "            ys = torch.from_numpy(np.array(ys)).float()\n",
    "            \n",
    "            # Append the tensors to the batch\n",
    "            batch_xs.append(xs)\n",
    "            batch_imgs.append(imgs)\n",
    "            batch_ys.append(ys)\n",
    "\n",
    "        # Convert the batches to torch tensors\n",
    "        batch_imgs = torch.stack(batch_imgs)\n",
    "        batch_xs = torch.stack(batch_xs)\n",
    "        batch_ys = torch.stack(batch_ys)\n",
    "        \n",
    "        return batch_imgs, batch_xs, batch_ys\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ujeYNSStERGn"
   },
   "outputs": [],
   "source": [
    "dataset = WeatherDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of strings dd-mm-yyyy from 01-06-2023 to 15-6-2024\n",
    "dataset.date_generation(\"01_01_2022\", \"15_06_2024\")\n",
    "date_generated = dataset.date_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation-test split\n",
    "train_len = int(0.7 * len(dataset.date_generated))\n",
    "valid_len = int(0.15 * len(dataset.date_generated))\n",
    "test_len = len(dataset.date_generated) - train_len - valid_len\n",
    "\n",
    "# Create date train, valdiation, test lists by random sampling\n",
    "date_trainset = np.random.choice(date_generated, train_len, replace=False)\n",
    "date_valid = np.random.choice([date for date in date_generated if date not in date_trainset], valid_len, replace=False)\n",
    "date_testset = [date for date in date_generated if date not in date_trainset and date not in date_valid]\n",
    "\n",
    "# Define the loaders for the train, validation, test sets, they will provide dates in format dd_mm_yyyy\n",
    "train_loader = torch.utils.data.DataLoader(date_trainset, batch_size = 5, shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(date_valid, batch_size = 5, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(date_testset, batch_size = 5, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "byxTeA5rUiuG"
   },
   "outputs": [],
   "source": [
    "class DeepWeather(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepWeather, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels = 7, out_channels = 8, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=(1,2,2), padding=(0,1,1))\n",
    "        self.dropout = nn.Dropout(p = 0.3)\n",
    "        self.bn1 = nn.BatchNorm3d(8)\n",
    "        self.conv2 = nn.Conv3d(in_channels = 8, out_channels = 16, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.bn2 = nn.BatchNorm3d(16)\n",
    "        self.conv3 = nn.Conv3d(in_channels = 16, out_channels = 32, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.bn3 = nn.BatchNorm3d(32)\n",
    "        self.conv4 = nn.Conv3d(in_channels = 32, out_channels = 64, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.bn4 = nn.BatchNorm3d(64)\n",
    "        self.conv5 = nn.Conv3d(in_channels = 64, out_channels = 128, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.bn5 = nn.BatchNorm3d(128)\n",
    "        self.conv6 = nn.Conv3d(in_channels = 128, out_channels = 7, kernel_size = (1, 3, 3), stride = 1)\n",
    "        self.bn6 = nn.BatchNorm3d(7)\n",
    "        # channels, height, width = 3, 6, 8\n",
    "\n",
    "        self.input_size = 10 # number of features in the input (weather data)\n",
    "        self.hidden_size = 4\n",
    "        self.num_layers = 1\n",
    "        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "\n",
    "        # dim input fc = seq_len * 3 * 6 * 8 + hidden_size = 1024\n",
    "        self.seq_len = 7\n",
    "        self.fc = nn.Linear(self.seq_len*3*6*8+self.hidden_size, 1)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \n",
    "        x1 = self.bn1(self.dropout(self.pool(F.leaky_relu(self.conv1(x1)))))\n",
    "        x1 = self.bn2(self.dropout(self.pool(F.leaky_relu(self.conv2(x1)))))\n",
    "        x1 = self.bn3(self.dropout(self.pool(F.leaky_relu(self.conv3(x1)))))\n",
    "        x1 = self.bn4(self.dropout(self.pool(F.leaky_relu(self.conv4(x1)))))\n",
    "        x1 = self.bn5(self.dropout(self.pool(F.leaky_relu(self.conv5(x1)))))\n",
    "        x1 = self.bn6(self.dropout(self.pool(F.leaky_relu(self.conv6(x1)))))\n",
    "        print(\"x1 shape:\", x1.shape)\n",
    "        out_cnn = torch.flatten(x1, start_dim = 1)\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x2.size(0),self.hidden_size).to(x2.device)\n",
    "        out_rnn, _ = self.rnn(x2, h0)\n",
    "\n",
    "        out = torch.cat((out_rnn[:,-1,:], out_cnn), dim = 1)\n",
    "        print(\"out_rnn[:,-1,:] shape:\", out_rnn[:,-1,:].shape)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pXkUaJmmefOg"
   },
   "outputs": [],
   "source": [
    "def train(model, dataset, train_loader, test_loader, criterion, optimizer, epochs = 50, first_time = True, num_saved_epochs = 0):\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model = model.to(device)    \n",
    "    \n",
    "    train_loss_epochs = []\n",
    "    valid_loss_epochs = []\n",
    "    bar = trange(epochs, desc=f\"Epoch ?/?, Train Loss: ?, Test Loss: ?\")\n",
    "    \n",
    "    for epoch in bar:\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "            \n",
    "        for date in train_loader:\n",
    "            imgs, xs, ys = dataset.create_sequence(date, 7)\n",
    "            imgs = imgs.to(device)\n",
    "            xs = xs.to(device)\n",
    "            ys = ys.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs, xs)\n",
    "            loss = criterion(outputs, ys)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "        train_loss_epochs.append(np.mean(train_losses))\n",
    "        \n",
    "        model.eval()\n",
    "        valid_losses = []\n",
    "        for date in valid_loader:\n",
    "            \n",
    "            imgs, xs, ys = dataset.create_sequence(date, 7)\n",
    "            imgs = imgs.to(device)\n",
    "            xs = xs.to(device)\n",
    "            ys = ys.to(device)\n",
    "            outputs = model(imgs, xs)\n",
    "            loss = criterion(outputs.squeeze(), ys)\n",
    "            valid_losses.append(loss.item())\n",
    "                \n",
    "        valid_loss_epochs.append(np.mean(valid_losses))\n",
    "        bar.set_description(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {np.mean(train_losses)}, Validation Loss: {np.mean(valid_losses)}\")\n",
    "\n",
    "    return train_loss_epochs, valid_loss_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AKV2X85RFp7S"
   },
   "outputs": [],
   "source": [
    "model = DeepWeather()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 10e-6, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RwAo5dpaH9lH",
    "outputId": "046fb4bb-e399-46ee-d141-df943fcd47ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch ?/?, Train Loss: ?, Test Loss: ?:   0%|                                             | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 shape: torch.Size([5, 7, 3, 6, 8])\n",
      "out_rnn[:,-1,:] shape: torch.Size([5, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([5, 1, 1, 10])) that is different to the input size (torch.Size([5, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "Epoch ?/?, Train Loss: ?, Test Loss: ?:   0%|                                             | 0/50 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[Errno 2] No such file or directory: 'data/cut_images/17_06_2024.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_saved_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, train_loader, test_loader, criterion, optimizer, epochs, first_time, num_saved_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m---> 15\u001b[0m     imgs, xs, ys \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     imgs \u001b[38;5;241m=\u001b[39m imgs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     xs \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[3], line 111\u001b[0m, in \u001b[0;36mWeatherDataset.create_sequence\u001b[0;34m(self, dates_list, len_seq)\u001b[0m\n\u001b[1;32m    108\u001b[0m end_date_next \u001b[38;5;241m=\u001b[39m end_date_next\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Append the target value to ys\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m ys\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mend_date_next\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column_index])\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Convert the lists to torch tensors\u001b[39;00m\n\u001b[1;32m    114\u001b[0m imgs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(imgs))\u001b[38;5;241m.\u001b[39mfloat()\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mWeatherDataset.__getitem__\u001b[0;34m(self, start_date)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Get the image for the such start_date\u001b[39;00m\n\u001b[1;32m     42\u001b[0m image \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir, \u001b[38;5;28mstr\u001b[39m(start_date) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[0;32m---> 43\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mread_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [image, weather_data]\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/io/image.py:275\u001b[0m, in \u001b[0;36mread_image\u001b[0;34m(path, mode, apply_exif_orientation)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m    274\u001b[0m     _log_api_usage_once(read_image)\n\u001b[0;32m--> 275\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decode_image(data, mode, apply_exif_orientation\u001b[38;5;241m=\u001b[39mapply_exif_orientation)\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torchvision/io/image.py:52\u001b[0m, in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[1;32m     51\u001b[0m     _log_api_usage_once(read_file)\n\u001b[0;32m---> 52\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/orfeo/cephfs/home/dssc/adellasiega/jupyter/lib64/python3.9/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [Errno 2] No such file or directory: 'data/cut_images/17_06_2024.jpg'"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train(model, dataset, train_loader, test_loader, criterion, optimizer, epochs = 50, first_time = True, num_saved_epochs = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [epoch for epoch in range(50)]\n",
    "plt.plot(epochs, train_losses, label = 'Training Loss')\n",
    "plt.plot(epochs, val_losses, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model using the test loader\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)  \n",
    "model.eval()\n",
    "test_losses = []\n",
    "true = []\n",
    "predicted = []\n",
    "for date in test_loader:\n",
    "    imgs, xs, ys = dataset.create_sequence(date, 7)\n",
    "    imgs = imgs.to(device)\n",
    "    xs = xs.to(device)\n",
    "    ys = ys.to(device)\n",
    "    outputs = model(imgs, xs)\n",
    "    true.append(ys.cpu().detach().numpy())\n",
    "    predicted.append(outputs.cpu().detach().numpy())\n",
    "    loss = criterion(outputs.squeeze(), ys)\n",
    "    test_losses.append(loss.item())\n",
    "        \n",
    "print(f\"Mean Test Loss: {np.mean(test_losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
