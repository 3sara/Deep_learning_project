{"cells":[{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.io import read_image\n","import torchvision.transforms as T\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from sklearn.metrics import r2_score\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","from jupyterplot import ProgressPlot\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:21.669203Z","iopub.status.busy":"2021-12-11T21:10:21.668890Z","iopub.status.idle":"2021-12-11T21:10:21.681997Z","shell.execute_reply":"2021-12-11T21:10:21.681241Z","shell.execute_reply.started":"2021-12-11T21:10:21.669158Z"},"id":"aa9ssRQXOF9F","trusted":true},"outputs":[],"source":["class WeatherDataset(Dataset):\n","    def __init__(self, weather_data = 'data/arpafvg_fllbandiera_clean.csv', img_dir = 'data/images'):\n","        self.weather_data = pd.read_csv(weather_data)\n","        self.img_dir = img_dir\n","\n","    def __getitem__(self, date):\n","        #get day month year from date in format dd-mm-yyyy\n","        day, month, year = date.split('_')\n","        #get from weather data the row with the same date\n","        weather_data = self.weather_data[(self.weather_data['giorno'] == int(day)) & (self.weather_data['mese'] == int(month)) & (self.weather_data['anno'] == int(year))]\n","        weather_data = torch.tensor(weather_data.values[0])\n","\n","        image = os.path.join(self.img_dir, str(date) + '.jpg')  \n","        image = read_image(image)   \n","        return [image, weather_data]\n","    \n","    def __len__(self):\n","        return len(self.weather_data)"]},{"cell_type":"code","execution_count":99,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:22.449623Z","iopub.status.busy":"2021-12-11T21:10:22.449068Z","iopub.status.idle":"2021-12-11T21:10:22.496552Z","shell.execute_reply":"2021-12-11T21:10:22.495812Z","shell.execute_reply.started":"2021-12-11T21:10:22.449578Z"},"id":"ujeYNSStERGn","trusted":true},"outputs":[],"source":["dataset = WeatherDataset()"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["#generate a list of strings dd-mm-yyyy from 01-06-2023 to 15-6-2024\n","from datetime import datetime, timedelta\n","start_date = datetime.strptime(\"01_06_2023\", \"%d_%m_%Y\")\n","end_date = datetime.strptime(\"15_06_2024\", \"%d_%m_%Y\")\n","date_generated = [start_date + timedelta(days=x) for x in range(0, (end_date-start_date).days)]\n","#transform the list of datetime objects in a list of strings in format dd-mm-yyyy\n","date_generated = [date.strftime(\"%d_%m_%Y\") for date in date_generated]\n"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["train_len = int(0.8 * len(date_generated))\n","test_len = len(date_generated) - train_len\n","#split the dataset: date_trainset contains the first 80% of the dates, date_testset contains the remaining 20%\n","date_trainset = date_generated[:train_len]\n","date_testset = date_generated[train_len:]"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T00:03:40.391408Z","iopub.status.busy":"2021-12-12T00:03:40.390672Z","iopub.status.idle":"2021-12-12T00:03:40.740627Z","shell.execute_reply":"2021-12-12T00:03:40.737438Z","shell.execute_reply.started":"2021-12-12T00:03:40.391370Z"},"id":"JnZwz9bLHcHA","outputId":"c8f79255-4209-4216-c1b4-3ac1383550cb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.0230e+03, 7.0000e+00, 1.2000e+01, 8.8000e+00, 2.1600e+01, 2.6400e+01,\n","        3.1200e+01, 4.2000e+01, 6.6000e+01, 7.7000e+01, 1.3000e+01, 9.0000e+01,\n","        3.4700e+02, 2.1979e+04, 1.0139e+03], dtype=torch.float64)\n","tensor([[[171, 171, 172,  ...,  47,  37,  56],\n","         [171, 172, 172,  ...,  61,  50,  40],\n","         [171, 172, 172,  ...,  45,  47,  49],\n","         ...,\n","         [126, 126, 126,  ...,  65,  65,  65],\n","         [126, 126, 126,  ...,  66,  66,  66],\n","         [126, 126, 126,  ...,  66,  66,  66]],\n","\n","        [[169, 169, 170,  ...,  48,  38,  57],\n","         [169, 170, 170,  ...,  62,  51,  41],\n","         [169, 170, 170,  ...,  46,  48,  50],\n","         ...,\n","         [127, 127, 127,  ...,  68,  68,  68],\n","         [127, 127, 127,  ...,  69,  69,  69],\n","         [127, 127, 127,  ...,  69,  69,  69]],\n","\n","        [[174, 174, 175,  ...,  50,  40,  59],\n","         [174, 175, 175,  ...,  64,  53,  43],\n","         [174, 175, 175,  ...,  48,  50,  52],\n","         ...,\n","         [132, 132, 132,  ...,  73,  73,  73],\n","         [132, 132, 132,  ...,  74,  74,  74],\n","         [132, 132, 132,  ...,  74,  74,  74]]], dtype=torch.uint8)\n"]}],"source":["(image, weather_data) = dataset[date_generated[np.random.randint(low = 0, high = len(dataset))]]\n","print(weather_data)\n","print(image)\n"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:26.971066Z","iopub.status.busy":"2021-12-11T21:10:26.970091Z","iopub.status.idle":"2021-12-11T21:10:26.984961Z","shell.execute_reply":"2021-12-11T21:10:26.984072Z","shell.execute_reply.started":"2021-12-11T21:10:26.971013Z"},"id":"byxTeA5rUiuG","trusted":true},"outputs":[],"source":["class DeepWeather(nn.Module):\n","    def __init__(self):\n","        super(DeepWeather, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = (3, 3), stride = 2)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.dropout = nn.Dropout(p = 0.3)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (3, 3), stride = 2)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = (3, 3), stride = 2)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.fc1 = nn.Linear(6277, 1024)\n","        self.fc2 = nn.Linear(1024, 128)\n","        self.fc3 = nn.Linear(128, 1)\n","\n","    def forward(self, inputs):\n","        x1, x2 = inputs[0], inputs[1]\n","        \n","\n","        x1 = self.bn1(self.dropout(self.pool(F.leaky_relu(self.conv1(x1)))))\n","        x1 = self.bn2(self.dropout(self.pool(F.leaky_relu(self.conv2(x1)))))\n","        x1 = self.bn3(self.dropout(self.pool(F.leaky_relu(self.conv3(x1)))))\n","        x1 = torch.flatten(x1, start_dim = 1)\n","\n","        x = torch.cat((x1, x2), dim = 1)\n","        x = F.leaky_relu(self.fc1(x))\n","        x = F.leaky_relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":104,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:10:28.390345Z","iopub.status.busy":"2021-12-11T21:10:28.389014Z","iopub.status.idle":"2021-12-11T21:10:28.405412Z","shell.execute_reply":"2021-12-11T21:10:28.404512Z","shell.execute_reply.started":"2021-12-11T21:10:28.390295Z"},"id":"pXkUaJmmefOg","trusted":true},"outputs":[],"source":["def train(model, dataset, date_trainloader, date_testloader, criterion, optimizer, epochs, first_time = True, num_saved_epochs = 0):\n","    train_loss_epochs = []\n","    test_loss_epochs = []\n","    for epoch in range(epochs):\n","        model.train()\n","        train_losses = []\n","        for date_inputs in tqdm(date_trainloader):\n","            inputs = dataset[date_inputs[0]]\n","\n","\n","            #increment of 1 day the date_inputs\n","            date_next_day = date_inputs[0].split('_')\n","            date_next_day = datetime(int(date_next_day[2]), int(date_next_day[1]), int(date_next_day[0])) + timedelta(days = 1)\n","            date_next_day = date_next_day.strftime(\"%d_%m_%Y\")\n","\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, dataset[date_next_day][1][3])\n","            loss.backward()\n","            optimizer.step()\n","            train_losses.append(loss.item())\n","        train_loss_epochs.append(torch.mean(train_losses))\n","        model.eval()\n","        test_losses = []\n","        for date_inputs in tqdm(date_testloader):\n","            inputs = dataset[date_inputs[0]]\n","            outputs = model(inputs)\n","\n","            #increment of 1 day the date_inputs\n","            date_next_day = date_inputs[0].split('_')\n","            date_next_day = datetime(int(date_next_day[2]), int(date_next_day[1]), int(date_next_day[0])) + timedelta(days = 1)\n","            date_next_day = date_next_day.strftime(\"%d_%m_%Y\")\n","\n","            loss = criterion(outputs, dataset[date_next_day][1][3])\n","            test_losses.append(loss.item())\n","        test_loss_epochs.append(torch.mean(test_losses))\n","        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {torch.mean(train_losses)}, Test Loss: {torch.mean(test_losses)}\")\n","        if first_time:\n","            torch.save(model.state_dict(), f\"deepweather_epoch{num_saved_epochs + epoch + 1}.pth\")\n","\n","    return train_losses, test_losses"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:11:50.797058Z","iopub.status.busy":"2021-12-11T21:11:50.796756Z","iopub.status.idle":"2021-12-11T21:11:50.865574Z","shell.execute_reply":"2021-12-11T21:11:50.864806Z","shell.execute_reply.started":"2021-12-11T21:11:50.797026Z"},"id":"AKV2X85RFp7S","trusted":true},"outputs":[],"source":["#Uncomment the lines below if you want to train/load a pretrained model\n","#num_saved_epochs = 50\n","#model = model.load_state_dict(torch.load(f'weights/epoch_{num_saved_epochs}'))\n","\n","#Comment the (ONE) line below if you want to train/load a pretrained model.\n","#!mkdir weights\n","model = DeepWeather()\n","\n","date_trainloader = DataLoader(date_trainset, batch_size = 1, shuffle = True)\n","date_testloader = DataLoader(date_testset, batch_size = 1, shuffle = True)\n","\n","criterion = torch.nn.MSELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)"]},{"cell_type":"code","execution_count":106,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T21:11:56.070555Z","iopub.status.busy":"2021-12-11T21:11:56.069987Z","iopub.status.idle":"2021-12-11T21:58:07.613702Z","shell.execute_reply":"2021-12-11T21:58:07.612981Z","shell.execute_reply.started":"2021-12-11T21:11:56.070515Z"},"id":"RwAo5dpaH9lH","outputId":"046fb4bb-e399-46ee-d141-df943fcd47ff","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/304 [00:00<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"Input type (unsigned char) and bias type (float) should be the same","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_trainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_testloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_saved_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[104], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, date_trainloader, date_testloader, criterion, optimizer, epochs, first_time, num_saved_epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m date_next_day \u001b[38;5;241m=\u001b[39m date_next_day\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, dataset[date_next_day][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[103], line 21\u001b[0m, in \u001b[0;36mDeepWeather.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m     18\u001b[0m     x1, x2 \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m))))\n\u001b[1;32m     22\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x1)))))\n\u001b[1;32m     23\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mleaky_relu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x1)))))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"]}],"source":["train_losses, val_losses = train(model, dataset, date_trainloader, date_testloader, criterion, optimizer, epochs = 50, first_time = True, num_saved_epochs = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T22:00:59.350075Z","iopub.status.busy":"2021-12-11T22:00:59.349779Z","iopub.status.idle":"2021-12-11T22:00:59.545624Z","shell.execute_reply":"2021-12-11T22:00:59.544952Z","shell.execute_reply.started":"2021-12-11T22:00:59.350041Z"},"trusted":true},"outputs":[],"source":["epochs = [epoch for epoch in range(50)]\n","plt.plot(epochs, train_losses, label = 'Training Loss')\n","plt.plot(epochs, val_losses, label = 'Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T22:10:20.948734Z","iopub.status.busy":"2021-12-11T22:10:20.948080Z","iopub.status.idle":"2021-12-11T22:10:20.954384Z","shell.execute_reply":"2021-12-11T22:10:20.953403Z","shell.execute_reply.started":"2021-12-11T22:10:20.948700Z"},"trusted":true},"outputs":[],"source":["def predict(model, dataset, inputs):\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    \n","    model = model.to(device)\n","    inputs[0] = inputs[0].float().to(device)\n","    inputs[1] = inputs[1].float().to(device)\n","    \n","    outputs = model(inputs)\n","    outputs = (outputs.cpu().detach().numpy() * dataset.labels_std) + dataset.labels_means\n","    \n","    return outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-12T00:04:30.252221Z","iopub.status.busy":"2021-12-12T00:04:30.251516Z","iopub.status.idle":"2021-12-12T00:04:30.289045Z","shell.execute_reply":"2021-12-12T00:04:30.288358Z","shell.execute_reply.started":"2021-12-12T00:04:30.252182Z"},"trusted":true},"outputs":[],"source":["data = valset[np.random.randint(low = 0, high = len(valset))]\n","\n","inputs = data[0]\n","inputs[0] = inputs[0].unsqueeze(0)\n","inputs[1] = inputs[1].unsqueeze(0)\n","\n","label = (data[1] * dataset.labels_std) + dataset.labels_means\n","forecast = (inputs[1] * dataset.forecasts_std) + dataset.forecasts_means\n","\n","prediction = predict(model, dataset, inputs)\n","\n","forecast = forecast.squeeze()\n","prediction = prediction.squeeze()\n","\n","print(f\"Forecast:\\n    Average Temp: {forecast[0]:.2f}K    Min Temp: {forecast[1]:.2f}K    Max Temp: {forecast[2]:.2f}K    Humidity: {forecast[4]:.2f}%    Clouds: {forecast[3]:.2f}%\")\n","print(f\"\\nLabel:\\n    Average Temp: {label[0]:.2f}K    Min Temp: {label[1]:.2f}K    Max Temp: {label[2]:.2f}K    Humidity: {label[3]:.2f}%\")\n","print(f\"\\nPrediction:\\n    Average Temp: {prediction[0]:.2f}K    Min Temp: {prediction[1]:.2f}K    Max Temp: {prediction[2]:.2f}K    Humidity: {prediction[3]:.2f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-11T23:35:22.171676Z","iopub.status.busy":"2021-12-11T23:35:22.171409Z","iopub.status.idle":"2021-12-11T23:37:11.661566Z","shell.execute_reply":"2021-12-11T23:37:11.659906Z","shell.execute_reply.started":"2021-12-11T23:35:22.171646Z"},"trusted":true},"outputs":[],"source":["trainloader = DataLoader(trainset, batch_size = 128, shuffle = False)\n","train_r2 = 0\n","train_avg_temp_r2 = 0\n","train_min_temp_r2 = 0\n","train_max_temp_r2 = 0\n","train_humidity_r2 = 0\n","for i, data in enumerate(trainloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    labels = (labels * dataset.labels_std) + dataset.labels_means\n","    \n","    outputs = predict(model, dataset, inputs)\n","    \n","    train_r2 += r2_score(labels, outputs)\n","    train_avg_temp_r2 += r2_score(labels[:, 0], outputs[:, 0])\n","    train_min_temp_r2 += r2_score(labels[:, 1], outputs[:, 1])\n","    train_max_temp_r2 += r2_score(labels[:, 2], outputs[:, 2])\n","    train_humidity_r2 += r2_score(labels[:, 3], outputs[:, 3])\n","    \n","train_r2 /= len(trainloader)\n","train_avg_temp_r2 /= len(trainloader)\n","train_min_temp_r2 /= len(trainloader)\n","train_max_temp_r2 /= len(trainloader)\n","train_humidity_r2 /= len(trainloader)\n","\n","print(\"Training Data R2 Scores:\")\n","print(f\"    Avg Temp: {train_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {train_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {train_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {train_humidity_r2:.3f}\")\n","print(f\"    Total: {train_r2:.3f}\")\n","    \n","    \n","    \n","    \n","valloader = DataLoader(valset, batch_size = 128, shuffle = False)\n","val_r2 = 0\n","val_avg_temp_r2 = 0\n","val_min_temp_r2 = 0\n","val_max_temp_r2 = 0\n","val_humidity_r2 = 0\n","for i, data in enumerate(valloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    labels = (labels * dataset.labels_std) + dataset.labels_means\n","    \n","    outputs = predict(model, dataset, inputs)\n","    \n","    val_r2 += r2_score(labels, outputs)\n","    val_avg_temp_r2 += r2_score(labels[:, 0], outputs[:, 0])\n","    val_min_temp_r2 += r2_score(labels[:, 1], outputs[:, 1])\n","    val_max_temp_r2 += r2_score(labels[:, 2], outputs[:, 2])\n","    val_humidity_r2 += r2_score(labels[:, 3], outputs[:, 3])\n","    \n","val_r2 /= len(valloader)\n","val_avg_temp_r2 /= len(valloader)\n","val_min_temp_r2 /= len(valloader)\n","val_max_temp_r2 /= len(valloader)\n","val_humidity_r2 /= len(valloader)\n","\n","print(\"\\nValidation Data R2 Scores:\")\n","print(f\"    Avg Temp: {val_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {val_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {val_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {val_humidity_r2:.3f}\")\n","print(f\"    Total: {val_r2:.3f}\")\n","\n","\n","\n","\n","dataloader = DataLoader(dataset, batch_size = 128)\n","forecast_r2 = 0\n","forecast_avg_temp_r2 = 0\n","forecast_min_temp_r2 = 0\n","forecast_max_temp_r2 = 0\n","forecast_humidity_r2 = 0\n","for i, data in enumerate(dataloader):\n","    inputs = data[0]\n","    labels = data[1]\n","    forecasts = inputs[1]\n","    forecasts = forecasts[:, np.r_[:3, 4]]\n","    \n","    forecast_avg_temp_r2 += r2_score(labels[:, 0], forecasts[:, 0])\n","    forecast_min_temp_r2 += r2_score(labels[:, 1], forecasts[:, 1])\n","    forecast_max_temp_r2 += r2_score(labels[:, 2], forecasts[:, 2])\n","    forecast_humidity_r2 += r2_score(labels[:, 3], forecasts[:, 3])\n","    forecast_r2 += r2_score(forecasts, labels)\n","    \n","forecast_r2 /= len(dataloader)\n","forecast_avg_temp_r2 /= len(dataloader)\n","forecast_min_temp_r2 /= len(dataloader)\n","forecast_max_temp_r2 /= len(dataloader)\n","forecast_humidity_r2 /= len(dataloader)\n","\n","print(\"\\nForecast Data R2 Scores:\")\n","print(f\"    Avg Temp: {forecast_avg_temp_r2:.3f}\")\n","print(f\"    Min Temp: {forecast_min_temp_r2:.3f}\")\n","print(f\"    Max Temp: {forecast_max_temp_r2:.3f}\")\n","print(f\"    Humidity: {forecast_humidity_r2:.3f}\")\n","print(f\"    Total: {forecast_r2:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
